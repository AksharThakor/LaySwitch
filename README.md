# ğŸ“±LaySwitch: Handedness Detection Using IMU Data

### Real-time left / right / both hand detection for smartphones using IMU sensors and Deep Learning

---

## ğŸ§­ Overview

This project demonstrates a complete end-to-end system for **detecting which hand a user is using to interact with their smartphone** â€” left, right, or both â€” using only **IMU (Inertial Measurement Unit)** data collected from the device.

It includes:

- **Two Android applications**
  - ğŸ“² **IMUData_Handedness** â€“ for recording labeled IMU data  
  - âš™ï¸ **HandednessDetector** â€“ for performing real-time inference using a trained model
- **A training pipeline** based on a **1D Convolutional Neural Network (1D-CNN)**
- **Supporting scripts and data-handling tools**
- **Pre-trained model architecture and results**

The system serves as a **proof of concept** for future **OS-level or kernel-level handedness APIs**, enabling developers to adapt app interfaces dynamically based on which hand the user is using.

---

## ğŸ§© Project Structure

```
handedness-detection/
â”œâ”€â”€ AndroidStudioProjects/
â”‚   â”œâ”€â”€ IMUData_Handedness/           
â”‚   â””â”€â”€ HandednessDetector/           
â”‚
â”œâ”€â”€ Data/                             
â”‚
â”œâ”€â”€ Resources/
â”‚   â”œâ”€â”€ AppScreenshots/               
â”‚   â””â”€â”€ ModelArch/                    
â”‚
â”œâ”€â”€ Training.ipynb                    
â”œâ”€â”€ requirements.txt                  
â””â”€â”€ project_structure.txt             
```

---

## ğŸ§± Components

### 1. **IMUData_Handedness App**

This Android app is used to collect IMU data (Accelerometer + Gyroscope) for three conditions:

- **LEFT-hand usage**
- **RIGHT-hand usage**
- **BOTH-hands usage**

#### **How to Use**

1. Launch the app.  
2. Select one mode â€” **Left**, **Right**, or **Both**.
3. Tap **Start Recording**.  
   - You can minimize the app â€” it will continue recording in the background.
   - Use the phone naturally *only with the selected hand* while typing or using the device.
4. To stop recording:
   - Reopen the app and tap **Stop Recording**, **or**
   - Tap **Stop** from the **notification panel**.
5. If you make an error:
   - Tap **See Recordings**, open the **Recordings Screen**, and delete the incorrect file.

Automatic stop triggers:
- Screen off  
- Phone lock  
- No motion detected  

#### **Permissions**
- `ACTIVITY_RECOGNITION`
- `POST_NOTIFICATIONS`

#### **Export Data**
After 8â€“10 minutes per mode:
1. Tap **Export CSVs**
2. Transfer the ZIP file to PC
3. Extract into:

```
Data/
```

---

### 2. **Model Training**

Set up environment:

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

Run:

```
Training.ipynb
```

Outputs:
- Validation metrics  
- `.tflite` model for on-device inference  

---

### 3. **Model Architecture**

![Model Architecture](Resources/ModelArch/model%20arch%20mono.jpg)

- Input: `(120, 6)` at 60 Hz  
- Fixed normalization  
- 1Ã—1 calibration conv  
- Temporal 1D-CNN layers  
- Global Average Pooling  
- Dense classifier  
- Output classes: Left / Right / Both  

---

### 4. **HandednessDetector App**

Copy the trained model to:

```
HandednessDetector/app/src/main/assets/
```

Build APK in Android Studio.

#### **Usage**

- Tap text field  
- Keyboard opens  
- Real-time handedness predictions begin  
- Close keyboard â†’ predictions stop  

---

## âš™ï¸ Technical Summary

- Sensors: Accelerometer, Gyroscope  
- Sample rate: 60 Hz  
- Model: 1D CNN  
- Framework: TensorFlow Lite  
- Data: IMU windows (~8â€“10 min per mode)  

---

## ğŸ§  Vision

This project is a step toward **OS-level handedness APIs**, enabling adaptive UI layouts such as:

- Moving UI elements toward active thumb  
- Dynamic keyboard curvature  
- Reachability-aware layouts  
- Reducing false touches  

---

## ğŸ§‘â€ğŸ’» Workflow Summary

| Step | Description |
|------|-------------|
| **Collect Data** | Use IMUData_Handedness app |
| **Export CSVs** | Extract into `Data/` |
| **Train Model** | Run `Training.ipynb` |
| **Deploy Model** | Move `.tflite` into assets folder |
| **Run Inference** | Build and use HandednessDetector |

---

## ğŸ“¦ Requirements

- Python â‰¥ 3.9  
- TensorFlow â‰¥ 2.13  
- NumPy, Pandas, Scikitâ€‘learn  
- Android Studio (SDK 33+)  

---

## ğŸ™ Acknowledgements

Thanks to the guiding professor and colleagues who participated in IMU data collection and testing.

---

**Author:** Akshar Thakor  
**Version:** v1.0.0
